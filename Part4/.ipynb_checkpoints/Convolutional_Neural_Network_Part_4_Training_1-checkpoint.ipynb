{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from skimage.color import rgb2hsv\n",
    "#from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import keras\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "import cv2\n",
    "from matplotlib import pyplot\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Lambda\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import SpatialDropout2D\n",
    "from contextlib import redirect_stdout\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "import time\n",
    "import training_models\n",
    "import types\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double checking to ensure gpu is enabled for training\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(cwd+ '\\\\color_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv(r'C:\\Users\\abelp\\machine_learning\\crowd_count\\data\\count_.csv', names=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.columns = ['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = np.append(pkl.load(open(r'C:\\Users\\abelp\\machine_learning\\crowd_count\\final_data\\mean_normalized1.pkl', 'rb')),\n",
    "                  pkl.load(open(r'C:\\Users\\abelp\\machine_learning\\crowd_count\\final_data\\mean_normalized2.pkl', 'rb')),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_location = 'C:\\\\Users\\\\abelp\\\\machine_learning\\\\crowd_count\\\\models\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(model_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = input_.shape[1]\n",
    "IMG_SIZE2 = input_.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_ = training_models.models_to_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.array(target['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(input_, target, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "X_test = np.expand_dims(X_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_Generator():\n",
    "    while True:\n",
    "        for i in range(0,len(X_train) // 100):\n",
    "            time.sleep(0.01)\n",
    "            yield  X_train[i*10:(i+1)*10], y_train[i*10:(i+1)*10]\n",
    "            \n",
    "def train_model(method):        \n",
    "    filepath = model_location + method + '.h5'\n",
    "    \n",
    "    es_callback = EarlyStopping(monitor='mse', patience=5)\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_mse', save_best_only=True, mode='min')\n",
    "    \n",
    "    model = getattr(models_, method)(IMG_SIZE, IMG_SIZE2)\n",
    "\n",
    "    model.compile(optimizer='ADAM', loss='mse', metrics=['mse'])\n",
    "\n",
    "    with open('C:\\\\Users\\\\abelp\\\\machine_learning\\\\crowd_count\\\\model_summary\\\\augmented_' + method + '_summary.txt', 'w') as f:\n",
    "        with redirect_stdout(f):\n",
    "            model.summary()\n",
    "    \n",
    "    history = model.fit_generator(data_Generator(), steps_per_epoch=25, epochs=500,  callbacks=[es_callback, checkpoint], verbose=1, validation_data=(X_test, y_test))\n",
    "    \n",
    "    val_loss_dict[method] = min(history.history['val_mse'])\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(history.history['mse'][1:], label='train')\n",
    "    plt.plot(history.history['val_mse'][1:], label='test')\n",
    "    plt.title('train / test loss - ' + method)\n",
    "    plt.savefig(model_location + 'normalized_sample' + method + '.png')\n",
    "    \n",
    "    del history\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_methods = ['basic_CNN_v2_DO_LR', 'basic_CNN_v2_BN_LR', \"alex_net_trasfer\"]\n",
    "for method in exec_methods:\n",
    "    train_model(method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#, \"alex_net_trasfer_v2\", \"alex_net_trasfer_BE\", \"alex_net_trasfer_BE_LR\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
